# üïµÔ∏è‚Äç‚ôÇÔ∏è An√°lisis de Discrepancia: Optuna vs Ejecuci√≥n Manual

## ‚ùì Problema

**Optuna reporta una precisi√≥n del 80% con ciertos hiperpar√°metros, pero al ejecutar el sistema manualmente con esos mismos par√°metros, la precisi√≥n cae a ~43%.**

---

## 1. Posibles Causas T√©cnicas

### 1.1. Diferencia en la funci√≥n de recompensa
- **Optuna** podr√≠a estar usando una funci√≥n de recompensa diferente (por ejemplo, `np.linalg.norm([x, y])`), mientras que la ejecuci√≥n manual usa otra (por ejemplo, `-np.tanh(np.linalg.norm([x, y]) * 0.1)`).
- **Impacto:** Cambios sutiles en la funci√≥n de recompensa pueden alterar radicalmente el aprendizaje y la m√©trica de precisi√≥n.
- **Verificar:** Que el string de la funci√≥n de recompensa en `config.yaml` sea **id√©ntico** al usado en el trial de Optuna.

### 1.2. Semillas aleatorias y determinismo
- **Optuna** puede fijar la semilla (`numpy_seed`, `torch_seed`) de forma diferente o en un lugar distinto del c√≥digo respecto a la ejecuci√≥n manual.
- **Impacto:** En RL, peque√±as diferencias en la semilla pueden causar grandes variaciones en el resultado.
- **Verificar:** Que las semillas sean exactamente iguales y se fijen antes de cualquier inicializaci√≥n de red o buffer.

### 1.3. Diferencias en el pipeline de evaluaci√≥n
- **Optuna** podr√≠a estar evaluando la precisi√≥n de forma diferente (por ejemplo, usando un grid distinto, o evaluando en un punto diferente del entrenamiento).
- **Impacto:** Si la m√©trica de evaluaci√≥n no es id√©ntica, los resultados no son comparables.
- **Verificar:** Que el m√©todo de evaluaci√≥n (`evaluate_policy_grid`, etc.) sea exactamente el mismo en ambos casos.

### 1.4. Par√°metros ocultos o no aplicados
- Puede que algunos par√°metros del trial de Optuna no se est√©n aplicando realmente en la ejecuci√≥n manual (por ejemplo, si el c√≥digo no lee todos los par√°metros desde el config, o si hay un bug en la actualizaci√≥n de la configuraci√≥n).
- **Impacto:** Un solo par√°metro diferente puede cambiar radicalmente el resultado.
- **Verificar:** Que todos los par√°metros del trial ganador est√©n realmente en uso en la ejecuci√≥n manual.

### 1.5. Optuna sobreajustando a una m√©trica espec√≠fica
- Si la m√©trica de Optuna no es exactamente la misma que la reportada en el CLI, puede haber un sesgo.
- **Verificar:** Que la m√©trica de score/precisi√≥n sea exactamente la misma en ambos contextos.

### 1.6. Estado interno o inicializaci√≥n diferente
- Puede haber diferencias en el estado inicial del entorno, buffers, o incluso en la inicializaci√≥n de la red.
- **Verificar:** Que todo el pipeline de inicializaci√≥n sea id√©ntico.

---

## 2. Checklist de Verificaci√≥n

- [ ] ¬øLa funci√≥n de recompensa (`reward_function`) es **id√©ntica** en Optuna y en el config.yaml?
- [ ] ¬øLas semillas (`numpy_seed`, `torch_seed`) son iguales y se fijan antes de cualquier inicializaci√≥n?
- [ ] ¬øEl m√©todo de evaluaci√≥n es exactamente el mismo (grid, episodios, etc.)?
- [ ] ¬øTodos los hiperpar√°metros del trial ganador est√°n realmente aplicados en la ejecuci√≥n manual?
- [ ] ¬øNo hay par√°metros por defecto o "ocultos" que difieran?
- [ ] ¬øEl entorno y la red se inicializan exactamente igual?
- [ ] ¬øEl c√≥digo de entrenamiento y evaluaci√≥n es el mismo en ambos casos?
- [ ] ¬øNo hay diferencias en la versi√≥n de librer√≠as (numpy, torch, etc.)?

---

## 3. Recomendaciones para Depuraci√≥n

1. **Haz un diff entre el config.yaml y los par√°metros del trial ganador de Optuna.**
2. **Fuerza la funci√≥n de recompensa y todos los hiperpar√°metros a ser id√©nticos.**
3. **Imprime todos los hiperpar√°metros y la funci√≥n de recompensa al inicio de cada run.**
4. **Fuerza la semilla aleatoria antes de cualquier inicializaci√≥n.**
5. **Verifica que el m√©todo de evaluaci√≥n sea exactamente el mismo.**
6. **Ejecuta varias veces para descartar variabilidad estoc√°stica.**
7. **Si la discrepancia persiste, prueba a ejecutar el trial de Optuna manualmente (fuera del framework) con los mismos par√°metros y observa el resultado.**

---

## 4. Conclusi√≥n

**Las discrepancias entre Optuna y la ejecuci√≥n manual suelen deberse a diferencias sutiles en la funci√≥n de recompensa, semillas, par√°metros no aplicados o diferencias en el pipeline de evaluaci√≥n.**

**La reproducibilidad en RL es dif√≠cil, pero siguiendo este checklist puedes identificar y corregir la causa ra√≠z.**