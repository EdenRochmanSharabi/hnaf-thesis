# Hybrid Normalized Advantage Function (HNAF) - Tesis de Grado

## ğŸ“‹ DescripciÃ³n

Este repositorio contiene la implementaciÃ³n completa del **Hybrid Normalized Advantage Function (HNAF)** desarrollado como parte de la tesis de grado. El HNAF es un algoritmo de aprendizaje por refuerzo que combina control discreto y continuo para sistemas de control hÃ­bridos.

## ğŸ¯ Objetivo

Implementar y optimizar un algoritmo de aprendizaje por refuerzo hÃ­brido que pueda manejar sistemas de control con modos discretos y acciones continuas, aplicando las tÃ©cnicas de Normalized Advantage Function (NAF) a problemas de control hÃ­brido.

## ğŸ”¬ MetodologÃ­a

### Sistema de Control HÃ­brido
El sistema implementado consiste en un sistema de control con dos modos discretos:
- **Modo 0**: Matriz de transformaciÃ³n Aâ‚ = [[1, 50], [-1, 1]]
- **Modo 1**: Matriz de transformaciÃ³n Aâ‚‚ = [[1, -1], [50, 1]]

### Algoritmo HNAF
El HNAF combina:
- **SelecciÃ³n discreta de modos**: Îµ-greedy sobre los modos disponibles
- **Control continuo**: NAF para acciones continuas dentro de cada modo
- **Aprendizaje hÃ­brido**: OptimizaciÃ³n conjunta de modos y acciones

## ğŸš€ CaracterÃ­sticas Principales

### âœ… Mejoras Implementadas
1. **Recompensas reescaladas**: `r = -abs(||x'|| - ||xâ‚€||) / 15` para estabilidad numÃ©rica
2. **Factor de descuento optimizado**: Î³ = 0.9 para mejor convergencia
3. **ExploraciÃ³n Îµ-greedy forzada**: Balance entre explotaciÃ³n y exploraciÃ³n
4. **Buffer de replay ampliado**: 5000 transiciones para mejor experiencia
5. **Batch size optimizado**: 32 muestras para gradientes estables
6. **Entrenamiento extendido**: 1000 Ã©pocas para convergencia completa

### ğŸ”§ Componentes TÃ©cnicos
- **Arquitectura de red**: Redes neuronales separadas para cada modo
- **FunciÃ³n de valor**: V(x,v) para cada modo discreto
- **FunciÃ³n de ventaja**: A(x,v,u) para acciones continuas
- **ActualizaciÃ³n suave**: Soft update de redes objetivo
- **Clipping de gradientes**: Para estabilidad numÃ©rica

## ğŸ“ Estructura del Proyecto

```
HNAF-Jose/
â”œâ”€â”€ src/                          # MÃ³dulo principal
â”‚   â”œâ”€â”€ __init__.py              # InicializaciÃ³n del mÃ³dulo
â”‚   â”œâ”€â”€ hnaf_stable.py           # ImplementaciÃ³n HNAF mejorada
â”‚   â”œâ”€â”€ naf_corrected.py         # NAF corregido con exponencial de matriz
â”‚   â””â”€â”€ optimization_functions.py # Funciones de optimizaciÃ³n base
â”œâ”€â”€ demo_completo.py              # DemostraciÃ³n completa del sistema
â”œâ”€â”€ test_hnaf_improvements.py     # Tests de mejoras implementadas
â”œâ”€â”€ hnaf_stable.py                # ImplementaciÃ³n principal HNAF
â”œâ”€â”€ naf_corrected.py              # NAF corregido principal
â”œâ”€â”€ optimization_functions.py     # Funciones de optimizaciÃ³n
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ README.md                     # Este archivo
â””â”€â”€ RESUMEN_MEJORAS_HNAF.md      # DocumentaciÃ³n detallada de mejoras
```

## ğŸ› ï¸ InstalaciÃ³n

### Prerrequisitos
- Python 3.8+
- PyTorch
- NumPy
- SciPy
- Matplotlib

### InstalaciÃ³n de Dependencias
```bash
pip install -r requirements.txt
```

## ğŸ“– Uso

### DemostraciÃ³n Completa
Para ejecutar la demostraciÃ³n completa del sistema:
```bash
python demo_completo.py
```

### Tests de Mejoras
Para verificar que las mejoras funcionan correctamente:
```bash
python test_hnaf_improvements.py
```

### Entrenamiento Personalizado
```python
from src.hnaf_stable import train_stable_hnaf

# Entrenar HNAF con configuraciÃ³n mejorada
hnaf = train_stable_hnaf(num_episodes=1000, eval_interval=50)
```

## ğŸ“Š Resultados

### Rendimiento vs SoluciÃ³n Exacta
- **Recompensas reescaladas**: âœ… Implementadas correctamente
- **Gamma = 0.9**: âœ… Efecto significativo en convergencia
- **ExploraciÃ³n mejorada**: âœ… Îµ-greedy funcionando
- **Buffer y batch optimizados**: âœ… ConfiguraciÃ³n estable

### MÃ©tricas de Entrenamiento
- **Ã‰pocas de entrenamiento**: 1000
- **Intervalo de evaluaciÃ³n**: 50 Ã©pocas
- **Batch size**: 32
- **Buffer capacity**: 5000
- **Factor de descuento**: 0.9

## ğŸ”¬ ValidaciÃ³n CientÃ­fica

### ComparaciÃ³n con SoluciÃ³n Exacta
El sistema implementa la soluciÃ³n exacta usando exponencial de matriz:
```python
x(t) = expm(A * t) @ xâ‚€
```

### VerificaciÃ³n de CorrecciÃ³n
- âœ… Transformaciones usando exponencial de matriz
- âœ… Recompensas calculadas correctamente
- âœ… ComparaciÃ³n exitosa con soluciÃ³n ODE

## ğŸ“š Referencias

1. **Normalized Advantage Functions**: Gu et al. (2016)
2. **Hybrid Control Systems**: Branicky et al. (1998)
3. **Deep Reinforcement Learning**: Sutton & Barto (2018)

## ğŸ‘¨â€ğŸ“ Autor

**Eden Rochman**  
Estudiante de IngenierÃ­a  
Tesis de Grado

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto (Open Source).

## ğŸ¤ Contribuciones

Este es un proyecto de tesis acadÃ©mica. Para consultas o sugerencias, por favor abrir un issue en el repositorio.

## ğŸ“ Contacto

- **Email**: eden@example.com
- **GitHub**: [@edenrochman](https://github.com/edenrochman)

---

**Nota**: Este repositorio contiene el cÃ³digo completo de la tesis de grado sobre Hybrid Normalized Advantage Functions. El trabajo incluye implementaciÃ³n, optimizaciÃ³n y validaciÃ³n experimental del algoritmo HNAF para sistemas de control hÃ­bridos. 